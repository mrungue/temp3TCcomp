"""
Dashboard Interativo Streamlit - AnÃ¡lise TÃ©rmica 3TC
VisualizaÃ§Ã£o de dados de temperatura e correlaÃ§Ãµes
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from pathlib import Path
import re
from datetime import datetime, timedelta
from functools import lru_cache
from scipy import stats
from typing import Dict, List, Optional
from io import BytesIO
import requests
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lise TÃ©rmica 3TC",
    page_icon="ðŸŒ¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# FUNÃƒâ€¡Ãƒâ€¢ES AUXILIARES (mesmas do script principal)
# ============================================================================

def sniff_delim_and_encoding(filepath: Path):
    """Detecta delimitador e encoding do CSV"""
    with open(filepath, 'rb') as f:
        sample = f.read(4096)
        # Tenta encodings brasileiros primeiro (mais comum)
        for enc in ["latin-1", "cp1252", "iso-8859-1", "utf-8"]:
            try:
                text = sample.decode(enc, errors="ignore")
                semi = text.count(";")
                comma = text.count(",")
                return (";" if semi > comma else ","), enc
            except (UnicodeDecodeError, Exception):
                continue
    # Fallback seguro
    return ";", "latin-1"

def parse_sensor_id(filename: str) -> str:
    """Extrai ID do sensor do nome do arquivo"""
    m = re.search(r"(EL\d+)", filename)
    return m.group(1) if m else Path(filename).stem

def parse_timestamp_series(raw_series: pd.Series) -> pd.Series:
    """Parse de timestamps com mÃºltiplos formatos"""
    # Ordem de tentativa: formato ISO primeiro (mais comum nos CSVs dos sensores)
    # depois formatos brasileiros como fallback
    fmts = [
        "%Y-%m-%d %H:%M:%S",  # 2024-02-15 18:00:00 (FORMATO ISO - MAIS COMUM NOS CSVs)
        "%Y-%m-%d %H:%M",     # 2024-02-15 18:00
        "%d/%m/%Y %H:%M:%S",  # 15/02/2024 18:00:00 (formato brasileiro)
        "%d/%m/%Y %H:%M",     # 15/02/2024 18:00 (formato brasileiro)
        "%Y/%m/%d %H:%M:%S",  # 2024/02/15 18:00:00
        "%Y/%m/%d %H:%M",     # 2024/02/15 18:00
    ]
    
    for fmt in fmts:
        try:
            # Para formato ISO nÃ£o precisa dayfirst, para formato brasileiro sim
            dayfirst = fmt.startswith("%d/")
            ts = pd.to_datetime(raw_series, format=fmt, errors="coerce", utc=False, dayfirst=dayfirst)
            # Verifica se pelo menos 90% dos valores foram parseados corretamente
            if ts.notna().sum() > len(raw_series) * 0.9:
                return ts
        except Exception:
            continue
    
    # Fallback: tenta inferir automaticamente (tenta ambos os formatos)
    try:
        # Primeiro tenta sem dayfirst (formato ISO)
        ts = pd.to_datetime(raw_series, errors="coerce", utc=False, dayfirst=False, infer_datetime_format=False)
        if ts.notna().sum() > len(raw_series) * 0.9:
            return ts
    except Exception:
        pass
    
    try:
        # Depois tenta com dayfirst (formato brasileiro)
        ts = pd.to_datetime(raw_series, errors="coerce", utc=False, dayfirst=True, infer_datetime_format=False)
        if ts.notna().sum() > len(raw_series) * 0.9:
            return ts
    except Exception:
        pass
    
    # Ãšltimo recurso: retorna como estÃ¡ e deixa o pandas lidar (sem dayfirst por padrÃ£o)
    return pd.to_datetime(raw_series, errors="coerce", utc=False, dayfirst=False)


OPEN_METEO_GEOCODING_URL = "https://geocoding-api.open-meteo.com/v1/search"
OPEN_METEO_ARCHIVE_URL = "https://archive-api.open-meteo.com/v1/archive"


@lru_cache(maxsize=128)
def geocode_city(query: str, count: int = 5, country_code: str = None) -> List[Dict]:
    """Consulta a API de geocodificaÃ§Ã£o da Open-Meteo e retorna possÃ­veis cidades."""
    if not query or len(query.strip()) < 3:
        return []
    base = query.strip()
    search_terms = [base]
    if "," in base:
        primary = base.split(",", 1)[0].strip()
        if primary and primary not in search_terms:
            search_terms.append(primary)
    if " " in base:
        first_word = base.split(" ", 1)[0].strip()
        if first_word and first_word not in search_terms:
            search_terms.append(first_word)
    for term in search_terms:
        if len(term) < 3:
            continue
        params = {
            "name": term,
            "count": count * 2 if country_code else count,  # Busca mais se filtrar por paÃ­s
            "language": "pt",
            "format": "json"
        }
        # Adiciona filtro por paÃ­s se especificado
        if country_code:
            params["country_codes"] = country_code
        
        try:
            response = requests.get(OPEN_METEO_GEOCODING_URL, params=params, timeout=10)
            response.raise_for_status()
            payload = response.json()
            results = payload.get("results", [])
            if results:
                # Filtra apenas cidades do Brasil se country_code for BR
                if country_code:
                    results = [r for r in results if r.get('country_code', '').upper() == country_code.upper()]
                if results:
                    return results[:count]  # Retorna apenas o nÃºmero solicitado
        except Exception:
            continue
    return []


def fetch_external_temperature_from_api(
    latitude: float,
    longitude: float,
    start_ts: datetime,
    end_ts: datetime,
    tz: Optional[str] = None
) -> Optional[pd.DataFrame]:
    """Baixa temperatura externa horÃ¡ria via Open-Meteo para o perÃ­odo informado."""
    if start_ts is None or end_ts is None:
        return None
    
    try:
        start = pd.to_datetime(start_ts).tz_localize(None)
        end = pd.to_datetime(end_ts).tz_localize(None)
        if start > end:
            start, end = end, start
        
        # Verifica se as datas sÃ£o muito antigas (Open-Meteo Archive tem limitaÃ§Ãµes)
        # A API geralmente tem dados de 1940 atÃ© alguns dias atrÃ¡s
        hoje = pd.Timestamp.now()
        if end > hoje:
            end = hoje
        if start > hoje:
            return None
        
        params = {
            "latitude": float(latitude),
            "longitude": float(longitude),
            "start_date": start.date().isoformat(),
            "end_date": end.date().isoformat(),
            "hourly": "temperature_2m",
            "timezone": tz or "auto",
            "temperature_unit": "celsius"
        }
        
        response = requests.get(OPEN_METEO_ARCHIVE_URL, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        # Verifica se hÃ¡ erros na resposta
        if "error" in data:
            raise ValueError(f"API retornou erro: {data.get('reason', 'Erro desconhecido')}")
        
        hourly = data.get("hourly") or {}
        times = hourly.get("time")
        temps = hourly.get("temperature_2m")
        
        if not times or temps is None:
            # Tenta verificar se hÃ¡ mensagem de erro na resposta
            error_msg = data.get("error", {}).get("reason", "Resposta da API sem sÃ©rie de temperatura horÃ¡ria.")
            raise ValueError(f"API nÃ£o retornou dados: {error_msg}")
        
        if len(times) == 0 or len(temps) == 0:
            raise ValueError("API retornou lista vazia de dados de temperatura.")
        
        df = pd.DataFrame(
            {
                "timestamp": pd.to_datetime(times, errors="coerce"),
                "temp_externa": temps
            }
        )
        df = df.dropna(subset=["timestamp"]).set_index("timestamp").sort_index()
        
        if df.empty:
            return None
        
        df.index = df.index.tz_localize(None)
        return df
        
    except requests.exceptions.Timeout:
        raise Exception("Timeout ao consultar API Open-Meteo. Tente novamente.")
    except requests.exceptions.RequestException as e:
        raise Exception(f"Erro de conexÃ£o com API Open-Meteo: {str(e)}")
    except ValueError as e:
        raise
    except Exception as e:
        raise Exception(f"Erro inesperado ao buscar dados: {str(e)}")


def calcular_metricas_energeticas(df: pd.DataFrame, temp_max: float) -> Dict[str, Optional[float]]:
    """Calcula indicadores tÃ©rmicos chave usando temperatura interna e externa."""
    resultado: Dict[str, Optional[float]] = {
        "delta_t_medio": None,
        "delta_t_p95": None,
        "graus_hora_acima_limite": None,
        "slope_temp_ext_int": None,
        "corr_pearson": None,
        "lag_horas": None
    }

    if "temp_interna_media" not in df.columns or "temp_externa" not in df.columns:
        return resultado

    dados = df[["temp_interna_media", "temp_externa"]].dropna()
    if dados.empty:
        return resultado

    dados = dados.sort_index()
    delta_t = dados["temp_interna_media"] - dados["temp_externa"]
    resultado["delta_t_medio"] = float(delta_t.mean())
    resultado["delta_t_p95"] = float(delta_t.quantile(0.95))

    if isinstance(dados.index, pd.DatetimeIndex):
        dt_horas = dados.index.to_series().diff().dt.total_seconds().fillna(0) / 3600
        excedente = (dados["temp_interna_media"] - temp_max).clip(lower=0)
        resultado["graus_hora_acima_limite"] = float((excedente * dt_horas).sum())

        passo_medio_horas = dt_horas[dt_horas > 0].median()
        if pd.notna(passo_medio_horas) and passo_medio_horas > 0:
            int_vals = dados["temp_interna_media"].to_numpy()
            ext_vals = dados["temp_externa"].to_numpy()
            if len(int_vals) >= 3 and np.nanstd(int_vals) > 0 and np.nanstd(ext_vals) > 0:
                int_norm = int_vals - np.nanmean(int_vals)
                ext_norm = ext_vals - np.nanmean(ext_vals)
                corr = np.correlate(int_norm, ext_norm, mode="full")
                lags = np.arange(-len(int_norm) + 1, len(int_norm))
                melhor_idx = int(np.argmax(corr))
                lag_passos = lags[melhor_idx]
                resultado["lag_horas"] = float(lag_passos * passo_medio_horas)

    if dados["temp_externa"].nunique() > 1:
        slope, _, r_value, _, _ = stats.linregress(
            dados["temp_externa"],
            dados["temp_interna_media"]
        )
        resultado["slope_temp_ext_int"] = float(slope)
        resultado["corr_pearson"] = float(r_value)
    elif dados["temp_externa"].nunique() == 1 and dados["temp_interna_media"].nunique() == 1:
        resultado["slope_temp_ext_int"] = 0.0
        resultado["corr_pearson"] = 0.0

    return resultado


def render_metric_with_help(label: str, valor: Optional[str], ajuda: str, delta: Optional[str] = None):
    """Exibe mÃ©trica acompanhada de um popover com explicaÃ§Ã£o."""
    col_metric, col_help = st.columns([4, 1])
    with col_metric:
        st.metric(label, valor if valor is not None else "â€”", delta=delta)
    with col_help:
        with st.popover("?", use_container_width=True):
            st.write(ajuda)

def extract_metadata_from_csv(csv_file: Path) -> Dict:
    """Extrai metadados e informaÃ§Ãµes do CSV"""
    metadata = {
        "sensor_id": None,
        "modelo": None,
        "firmware": None,
        "tipo_sensor": None,
        "numero_viagem": None,
        "qualificacao": None,
        "fuso_horario": None,
        "intervalo_registro": None,
        "alarmes": {},
        "resumo": {},
        "arquivo_criado": None
    }
    
    try:
        sep, enc = sniff_delim_and_encoding(csv_file)
        sensor_id = parse_sensor_id(csv_file.name)
        metadata["sensor_id"] = sensor_id
        
        with open(csv_file, 'r', encoding=enc, errors='ignore') as f:
            lines = f.readlines()
        
        for i, line in enumerate(lines):
            line_lower = line.lower()
            
            # Arquivo criado em
            if "arquivo criado em" in line_lower:
                date_match = re.search(r"(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})", line)
                if date_match:
                    metadata["arquivo_criado"] = date_match.group(1)
            
            # Modelo
            if "modelo do dispositivo" in line_lower:
                parts = line.split(sep)
                if len(parts) >= 2:
                    metadata["modelo"] = parts[1].strip()
            
            # NÃºmero de sÃ©rie (jÃ¡ temos do parse_sensor_id)
            
            # Tipo de Sensor
            if "tipo de sensor" in line_lower:
                parts = line.split(sep)
                for p in parts:
                    if "temperatura" in p.lower() and "umidade" in p.lower():
                        metadata["tipo_sensor"] = p.strip()
                        break
            
            # Firmware
            if "versÃ£o do firmware" in line_lower or "versao do firmware" in line_lower:
                parts = line.split(sep)
                for p in parts:
                    if "v" in p.lower() and re.search(r"v\d+", p.lower()):
                        metadata["firmware"] = p.strip()
                        break
            
            # NÃºmero da Viagem
            if "nÃºmero da viagem" in line_lower and "000000" in line:
                parts = line.split(sep)
                for p in parts:
                    if re.match(r"\d{7}", p.strip()):
                        metadata["numero_viagem"] = p.strip()
            
            # QualificaÃ§Ã£o
            if "qualificacao" in line_lower or "qualifica" in line_lower:
                parts = line.split(sep)
                for p in parts:
                    if "qualificacao" in p.lower() or "qualifica" in p.lower():
                        metadata["qualificacao"] = p.strip()[:50]  # Limita tamanho
                        break
            
            # Fuso horÃ¡rio
            if "fuso horÃ¡rio" in line_lower or "fuso hor" in line_lower:
                parts = line.split(sep)
                for p in parts:
                    if "utc" in p.lower():
                        metadata["fuso_horario"] = p.strip()
                        break
            
            # Intervalo de registro
            if "intervalo de registro" in line_lower:
                parts = line.split(sep)
                for i, p in enumerate(parts):
                    if "intervalo" in p.lower():
                        if i + 1 < len(parts):
                            metadata["intervalo_registro"] = parts[i + 1].strip()
                            break
            
            # Alarmes H1, L1
            if "H1:" in line or "L1:" in line:
                parts = [p.strip() for p in line.split(sep) if p.strip()]
                if len(parts) >= 2:
                    tipo = parts[0].replace(":", "")
                    temp_match = re.search(r"(\d+[.,]\d+)", parts[1])
                    if temp_match:
                        temp_str = temp_match.group(1).replace(",", ".")
                        metadata["alarmes"][tipo] = {
                            "limite": float(temp_str),
                            "status": parts[-1] if len(parts) > 4 else None
                        }
            
            # Resumo - MÃ¡ximo, MÃ­nimo, MÃ©dia
            if "mÃ¡ximo" in line_lower or "mximo" in line_lower:
                temp_match = re.search(r"(\d+[.,]\d+)Â°c", line, re.IGNORECASE)
                if temp_match:
                    metadata["resumo"]["max_temp"] = float(temp_match.group(1).replace(",", "."))
            
            if "mÃ­nimo" in line_lower or "mnimo" in line_lower:
                temp_match = re.search(r"(\d+[.,]\d+)Â°c", line, re.IGNORECASE)
                if temp_match:
                    metadata["resumo"]["min_temp"] = float(temp_match.group(1).replace(",", "."))
            
            if "mÃ©dia" in line_lower or "mdia" in line_lower:
                temp_match = re.search(r"(\d+[.,]\d+)Â°c", line, re.IGNORECASE)
                if temp_match:
                    metadata["resumo"]["media_temp"] = float(temp_match.group(1).replace(",", "."))
            
            # MKT
            if "mkt" in line_lower:
                temp_match = re.search(r"(\d+[.,]\d+)", line)
                if temp_match:
                    metadata["resumo"]["mkt"] = float(temp_match.group(1).replace(",", "."))
            
            # Leituras Atuais
            if "leituras atuais" in line_lower or "leituras a" in line_lower:
                num_match = re.search(r"(\d+)", line)
                if num_match:
                    metadata["resumo"]["leituras_atuais"] = int(num_match.group(1))
            
            # Primeira/ÃƒÅ¡ltima leitura
            if "primeira leitura" in line_lower:
                date_match = re.search(r"(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2})", line)
                if date_match:
                    metadata["resumo"]["primeira_leitura"] = date_match.group(1)
            
            if "ultima leitura" in line_lower or "Ãºltima leitura" in line_lower:
                date_match = re.search(r"(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})", line)
                if date_match:
                    metadata["resumo"]["ultima_leitura"] = date_match.group(1)
    
    except Exception as e:
        pass  # Ignora erros de extraÃ§Ã£o de metadados
    
    return metadata

def load_internal_data(csv_dir: Path):
    """Carrega e processa dados dos sensores internos"""
    frames = []
    metadados_sensores = {}
    csv_files = list(csv_dir.glob("*.csv"))
    
    if not csv_files:
        return None, [], {}
    
    for csv_file in csv_files:
        try:
            sensor_id = parse_sensor_id(csv_file.name)
            
            # Extrai metadados do CSV
            metadata = extract_metadata_from_csv(csv_file)
            metadados_sensores[sensor_id] = metadata
            
            sep, enc = sniff_delim_and_encoding(csv_file)
            
            # Tenta ler com encoding detectado, se falhar tenta outros
            # Primeiro detecta onde comeÃ§am os dados (linha com cabeÃ§alho "NÃ£o.", "Tempo", etc.)
            skip_rows = None
            try:
                with open(csv_file, 'r', encoding=enc, errors='ignore') as f:
                    for i, raw_line in enumerate(f):
                        normalized = raw_line.replace('\ufeff', '')
                        cols = [
                            col.strip().lower()
                            for col in normalized.split(sep)
                            if col.strip()
                        ]
                        if not cols:
                            continue

                        cols_normalized = [
                            col.replace('Â°', '').replace('Ã‚Âº', '').replace('Ã¯Â¿Â½', '')
                            for col in cols
                        ]

                        has_tempo = any(col == 'tempo' for col in cols_normalized)
                        has_temp = any(
                            col.startswith('temperatura')
                            or col.startswith('temperaturac')
                            or (
                                col.startswith('temp')
                                and 'umidade' not in col
                                and 'umid' not in col
                                and 'rh' not in col
                            )
                            for col in cols_normalized
                        )

                        if has_tempo and has_temp:
                            skip_rows = i
                            break
            except Exception:
                pass
            
            df = None
            encodings_to_try = [enc, "latin-1", "cp1252", "iso-8859-1", "utf-8"]
            for encoding in encodings_to_try:
                try:
                    # Tenta com diferentes parÃ¢metros dependendo da versÃ£o do pandas
                    read_params = {
                        'sep': sep,
                        'encoding': encoding,
                        'engine': 'python'
                    }
                    if skip_rows is not None:
                        read_params['skiprows'] = skip_rows
                    
                    try:
                        read_params['on_bad_lines'] = 'skip'
                        df = pd.read_csv(csv_file, **read_params)
                    except TypeError:
                        # VersÃ£o antiga do pandas nÃ£o tem on_bad_lines
                        read_params.pop('on_bad_lines', None)
                        read_params['error_bad_lines'] = False
                        df = pd.read_csv(csv_file, **read_params)
                    break
                except (UnicodeDecodeError, Exception) as e:
                    if encoding == encodings_to_try[-1]:  # Ãšltimo encoding
                        raise e
                    continue
            
            if df is None or df.empty:
                continue
                
            df.columns = [str(c).strip() for c in df.columns]
            
            # Detecta timestamp (prioriza "Tempo" que Ã© o nome da coluna nos CSVs)
            ts_col = None
            for c in df.columns:
                cl = c.lower().strip()
                # Prioriza "tempo" que Ã© o nome exato da coluna nos CSVs
                if cl == "tempo":
                    ts_col = c
                    break
                elif any(k in cl for k in ["timestamp", "data e hora", "data/hora", "datahora", "data", "date", "hora", "time"]):
                    ts_col = c
                    break
            if ts_col is None:
                ts_col = df.columns[0]
            
            ts_raw = df[ts_col].astype(str)
            ts = parse_timestamp_series(ts_raw)
            
            # Detecta temperatura - PRIORIZA explicitamente "TemperaturaÂ°C"
            # EVITA colunas de umidade (Umidade%RH)
            t_col = None
            
            # ESTRATÃ‰GIA: Primeiro identifica TODAS as colunas candidatas
            # Depois valida pelos VALORES (nÃ£o sÃ³ pelo nome)
            candidatas_temp = []
            candidatas_umid = []
            
            for c in df.columns:
                if c == ts_col:
                    continue
                cl = c.lower().strip()
                c_orig = str(c).strip()
                
                # Identifica colunas de temperatura - mesmo com encoding corrompido
                # "TemperaturaÂ°C" pode aparecer como "TemperaturaC", "TemperaturaC", etc.
                # Remove caracteres nÃ£o-ASCII para comparaÃ§Ã£o mais robusta
                c_normalized = c_orig.replace('Â°', '').replace('', '').replace('\ufeff', '').strip()
                cl_normalized = c_normalized.lower()
                
                # Identifica colunas de temperatura (mesmo com Â° corrompido)
                # Procura por "temperatura" seguido opcionalmente por "c" ou "Â°c"
                has_temp = (
                    "temperatura" in cl or 
                    "temperatura" in cl_normalized or 
                    "temperaturac" in cl_normalized or
                    ("temp" in cl and "umidade" not in cl and "umid" not in cl and "rh" not in cl)
                )
                no_umidade = "umidade" not in cl and "umid" not in cl and "rh" not in cl
                
                if has_temp and no_umidade:
                    candidatas_temp.append(c)
                
                # Identifica colunas de umidade explicitamente
                if "umidade" in cl or "umid" in cl or "rh" in cl:
                    candidatas_umid.append(c)
            
            # VALIDAÃ‡ÃƒO POR VALORES: Testa cada candidata e escolhe a melhor
            melhor_col = None
            melhor_score = -1
            
            # Se nÃ£o encontrou candidatas por nome, adiciona TODAS as colunas (exceto umidade e timestamp)
            if not candidatas_temp:
                for c in df.columns:
                    if c != ts_col:
                        col_cl = c.lower().strip()
                        if "umidade" not in col_cl and "umid" not in col_cl and "rh" not in col_cl:
                            candidatas_temp.append(c)
            
            for col_candidata in candidatas_temp:
                try:
                    valores = pd.to_numeric(
                        df[col_candidata].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                        errors="coerce"
                    ).dropna()
                    
                    if len(valores) > 0:
                        media = valores.mean()
                        min_val = valores.min()
                        max_val = valores.max()
                        
                        # Score: melhor se mÃ©dia estÃ¡ entre 15-40Â°C (temperatura ambiente)
                        # Pior se mÃ©dia estÃ¡ entre 50-100 (umidade)
                        if 15 <= media <= 40 and min_val >= 10 and max_val <= 50:
                            score = 100 - abs(media - 30)  # Melhor quanto mais prÃ³ximo de 30Â°C
                            if score > melhor_score:
                                melhor_score = score
                                melhor_col = col_candidata
                except:
                    continue
            
            # Se nÃ£o encontrou candidata boa, tenta TODAS as colunas (exceto umidade e timestamp)
            # Isso garante que mesmo se o nome estiver corrompido, encontra pelos valores
            if melhor_col is None:
                for col_candidata in df.columns:
                    if col_candidata == ts_col:
                        continue
                    
                    # Pula colunas conhecidamente de umidade
                    col_cl = col_candidata.lower().strip()
                    if "umidade" in col_cl or "umid" in col_cl or "rh" in col_cl:
                        continue
                    
                    try:
                        valores = pd.to_numeric(
                            df[col_candidata].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                            errors="coerce"
                        ).dropna()
                        
                        if len(valores) > 0:
                            media = valores.mean()
                            min_val = valores.min()
                            max_val = valores.max()
                            
                            # Aceita se estÃ¡ na faixa de temperatura (15-40Â°C)
                            # E rejeita se estÃ¡ na faixa de umidade (50-100)
                            if 15 <= media <= 40 and min_val >= 10 and max_val <= 50 and media < 50:
                                melhor_col = col_candidata
                                break
                    except:
                        continue
            
            t_col = melhor_col
            
            # ValidaÃ§Ã£o crÃ­tica: verifica se a coluna detectada realmente Ã© temperatura
            if t_col is None:
                # ÃšLTIMO RECURSO: Tenta todas as colunas, mesmo sem validaÃ§Ã£o de nome
                # Isso resolve problemas de encoding corrompido
                for col_candidata in df.columns:
                    if col_candidata == ts_col:
                        continue
                    
                    col_cl = col_candidata.lower().strip()
                    # Pula apenas se for OBVIAMENTE umidade
                    if "umidade" in col_cl or ("umid" in col_cl and "rh" in col_cl):
                        continue
                    
                    try:
                        valores = pd.to_numeric(
                            df[col_candidata].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                            errors="coerce"
                        ).dropna()
                        
                        if len(valores) > 10:  # Precisa ter pelo menos alguns valores
                            media = valores.mean()
                            min_val = valores.min()
                            max_val = valores.max()
                            
                            # Se os valores estÃ£o na faixa de temperatura (10-50Â°C) E nÃ£o sÃ£o umidade (>50)
                            if 10 <= media <= 50 and min_val >= 5 and max_val <= 60 and media < 50:
                                t_col = col_candidata
                                st.info(f"Ã¢â€žÂ¹Ã¯Â¸Â Detectada coluna '{col_candidata}' como temperatura em {csv_file.name} (mÃ©dia: {media:.1f}Â°C)")
                                break
                    except:
                        continue
            
            # Se AINDA nÃ£o encontrou, tenta pela POSIÃ‡ÃƒO (geralmente temperatura Ã© a 3Âª coluna: NÃ£o., Tempo, Temperatura)
            if t_col is None and len(df.columns) >= 3:
                # Tenta a terceira coluna (depois de "NÃ£o." e "Tempo", geralmente Ã© "TemperaturaÂ°C")
                colunas_ordenadas = [c for c in df.columns if c != ts_col]
                # Pula a primeira coluna (geralmente "NÃ£o.") e pega a segunda (geralmente temperatura)
                if len(colunas_ordenadas) >= 2:
                    col_teste = colunas_ordenadas[1]  # Segunda coluna apÃ³s timestamp (Ã­ndice 1)
                elif len(colunas_ordenadas) >= 1:
                    col_teste = colunas_ordenadas[0]  # Primeira coluna disponÃ­vel
                else:
                    col_teste = None
                
                if col_teste:
                    try:
                        valores = pd.to_numeric(
                            df[col_teste].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                            errors="coerce"
                        ).dropna()
                        if len(valores) > 10:
                            media = valores.mean()
                            min_val = valores.min()
                            max_val = valores.max()
                            # Valida que nÃ£o Ã© umidade (umidade geralmente tem mÃ©dia > 50)
                            if 10 <= media <= 50 and min_val >= 5 and max_val <= 60:
                                t_col = col_teste
                                st.info(f"Ã¢â€žÂ¹Ã¯Â¸Â Usando coluna '{col_teste}' como temperatura (fallback por posiÃ§Ã£o) em {csv_file.name} (mÃ©dia: {media:.1f}Â°C)")
                    except:
                        pass
            
            if t_col is None:
                st.warning(f"Ã¢Å¡Â Ã¯Â¸Â NÃ£o foi possÃ­vel detectar coluna de temperatura em {csv_file.name}. Colunas disponÃ­veis: {df.columns.tolist()}")
                continue
            
            # Verifica se a coluna detectada nÃ£o Ã© umidade
            t_col_lower = t_col.lower().strip()
            if "umidade" in t_col_lower or "umid" in t_col_lower or "rh" in t_col_lower:
                # Se detectou umidade por engano, procura novamente excluindo esta
                t_col = None
                for c in df.columns:
                    cl = c.lower().strip()
                    if c == ts_col:
                        continue
                    if "temperatura" in cl or ("temp" in cl and "umidade" not in cl and "umid" not in cl and "rh" not in cl):
                        t_col = c
                        break
                if t_col is None:
                    st.warning(f"Ã¢Å¡Â Ã¯Â¸Â Apenas coluna de umidade encontrada em {csv_file.name}, pulando arquivo")
                    continue
            
            # Extrai valores da coluna detectada
            temp_raw = pd.to_numeric(
                df[t_col].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                errors="coerce"
            )
            
            # VALIDAÃ‡ÃƒO CRÃTICA ANTES DE USAR: Verifica se os valores fazem sentido para temperatura
            temp_validos = temp_raw.dropna()
            
            if len(temp_validos) == 0:
                st.warning(f"Ã¢Å¡Â Ã¯Â¸Â Nenhum valor vÃ¡lido na coluna '{t_col}' em {csv_file.name}")
                continue
            
            temp_media = temp_validos.mean()
            temp_min = temp_validos.min()
            temp_max = temp_validos.max()
            
            # VALIDAÃ‡ÃƒO: Se os valores estÃ£o claramente na faixa de umidade (40-100), TROCA de coluna
            if temp_min >= 40 and temp_max <= 100 and temp_media > 50:
                # Procura TODAS as outras colunas que possam ser temperatura
                coluna_corrigida = False
                for alt_col in df.columns:
                    if alt_col == t_col or alt_col == ts_col:
                        continue
                    
                    alt_cl = alt_col.lower().strip()
                    # REJEITA explicitamente colunas de umidade
                    if "umidade" in alt_cl or "umid" in alt_cl or "rh" in alt_cl:
                        continue
                    
                    # Tenta esta coluna alternativa
                    alt_temp = pd.to_numeric(
                        df[alt_col].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                        errors="coerce"
                    ).dropna()
                    
                    if len(alt_temp) > 0:
                        alt_media = alt_temp.mean()
                        alt_min = alt_temp.min()
                        alt_max = alt_temp.max()
                        
                        # Se a alternativa tem valores razoÃ¡veis para temperatura (10-50Â°C)
                        # e a mÃ©dia estÃ¡ abaixo de 50 (nÃ£o Ã© umidade)
                        if 10 <= alt_min and alt_max <= 50 and alt_media < 50:
                            # Esta Ã© provavelmente a coluna correta!
                            t_col = alt_col
                            temp_raw = alt_temp
                            coluna_corrigida = True
                            st.success(f"âœ… Corrigido automaticamente: '{csv_file.name}' - usando coluna '{alt_col}' (temperatura: {alt_media:.1f}Â°C) ao invÃ©s de '{t_col}' (umidade: {temp_media:.1f}%)")
                            break
                
                # Se nÃ£o conseguiu corrigir e ainda parece umidade, rejeita
                if not coluna_corrigida:
                    st.error(f"Ã¢ÂÅ’ ERRO: Coluna '{t_col}' contÃ©m valores de umidade (mÃ©dia: {temp_media:.1f}%) em {csv_file.name}. Pulando arquivo. Verifique se a coluna 'TemperaturaÂ°C' existe no CSV.")
                    continue
            
            # Usa a temperatura validada
            temp = temp_raw
            # Detecta umidade relativa associada ao sensor (se disponÃ­vel)
            u_col = None
            melhor_qtd = 0
            if candidatas_umid:
                for col_umid in candidatas_umid:
                    if col_umid == t_col or col_umid == ts_col:
                        continue
                    try:
                        valores_umid = pd.to_numeric(
                            df[col_umid].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                            errors="coerce"
                        ).dropna()
                        if len(valores_umid) == 0:
                            continue
                        umid_min = valores_umid.min()
                        umid_max = valores_umid.max()
                        umid_media = valores_umid.mean()
                        if 0 <= umid_min <= 100 and 0 < umid_max <= 100 and 0 < umid_media <= 100:
                            if len(valores_umid) > melhor_qtd:
                                melhor_qtd = len(valores_umid)
                                u_col = col_umid
                    except Exception:
                        continue

            umid_series = None
            if u_col:
                umid_series = pd.to_numeric(
                    df[u_col].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
                    errors="coerce"
                )
                if umid_series.notna().sum() == 0:
                    umid_series = None
                else:
                    metadados_sensores[sensor_id]["tem_umidade"] = True
                    metadados_sensores[sensor_id]["coluna_umidade_original"] = u_col

            cur = pd.DataFrame({
                "timestamp": ts,
                sensor_id: temp
            })
            if umid_series is not None:
                cur[f"{sensor_id}_umidade"] = umid_series
            cur = cur[~cur["timestamp"].isna()].sort_values("timestamp")
            
            # Garante que timestamp Ã© datetime64
            cur["timestamp"] = pd.to_datetime(cur["timestamp"], errors="coerce")
            cur = cur[~cur["timestamp"].isna()]
            
            # Remove valores invÃ¡lidos
            cur = cur[cur[sensor_id].notna()]
            
            if len(cur) == 0:
                continue
            
            frames.append(cur[["timestamp", sensor_id]])
            
        except Exception as e:
            st.warning(f"Erro ao processar {csv_file.name}: {e}")
            continue
    
    if not frames:
        return None, [], {}
    
    from functools import reduce
    wide = reduce(lambda L, R: pd.merge(L, R, on="timestamp", how="outer"), frames)
    
    # Garante que timestamp Ã© datetime antes de definir como Ã­ndice
    wide["timestamp"] = pd.to_datetime(wide["timestamp"], errors="coerce")
    wide = wide[~wide["timestamp"].isna()]
    wide = wide.set_index("timestamp").sort_index()
    
    # Garante que o Ã­ndice Ã© DatetimeIndex
    if not isinstance(wide.index, pd.DatetimeIndex):
        wide.index = pd.to_datetime(wide.index, errors="coerce")
        wide = wide[~wide.index.isna()]
    
    sensor_cols = [
        c for c in wide.columns
        if c.startswith("EL") and not c.lower().endswith("_umidade")
    ]
    wide["temp_interna_media"] = wide[sensor_cols].mean(axis=1)
    wide["temp_interna_min"] = wide[sensor_cols].min(axis=1)
    wide["temp_interna_max"] = wide[sensor_cols].max(axis=1)
    wide["temp_interna_std"] = wide[sensor_cols].std(axis=1)
    
    return wide, sensor_cols, metadados_sensores

def load_external_data(filepath: Path):
    """Carrega dados de temperatura externa"""
    if not filepath.exists():
        return None
    
    sep, enc = sniff_delim_and_encoding(filepath)
    df = pd.read_csv(filepath, sep=sep, encoding=enc)
    df.columns = [str(c).strip().lower() for c in df.columns]
    
    ts_col = None
    for c in df.columns:
        if any(k in c for k in ["timestamp", "data", "date", "hora", "time"]):
            ts_col = c
            break
    
    temp_col = None
    for c in df.columns:
        if any(k in c for k in ["temp", "temperatura", "celsius", "Â°c"]):
            if "extern" in c or ts_col is None or c != ts_col:
                temp_col = c
                break
    
    if ts_col is None or temp_col is None:
        return None
    
    ts = parse_timestamp_series(df[ts_col])
    temp = pd.to_numeric(
        df[temp_col].astype(str).str.replace(",", ".", regex=False).str.extract(r"([\-0-9\.]+)")[0],
        errors="coerce"
    )
    
    result = pd.DataFrame({
        "timestamp": ts,
        "temp_externa": temp
    }).dropna().set_index("timestamp").sort_index()
    
    return result

# ============================================================================
# FUNÃƒâ€¡Ãƒâ€¢ES DE VISUALIZAÃƒâ€¡ÃƒÆ’O
# ============================================================================

def plot_temperature_over_time(df, sensor_cols, show_external=True):
    """GrÃ¡fico de temperatura ao longo do tempo"""
    # Garante que o Ã­ndice Ã© DatetimeIndex (cria cÃ³pia para nÃ£o modificar original)
    df = df.copy()
    if not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index, errors="coerce")
        df = df[~df.index.isna()]
    
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        subplot_titles=("Temperatura Interna - Todos os Sensores", "Temperatura Interna - MÃ©dia e Faixa"),
        row_heights=[0.6, 0.4]
    )
    
    # GrÃ¡fico 1: Todos os sensores
    colors = px.colors.qualitative.Set3
    for i, sensor in enumerate(sensor_cols):
        fig.add_trace(
            go.Scatter(
                x=df.index,
                y=df[sensor],
                name=sensor,
                mode='lines',
                line=dict(width=1, color=colors[i % len(colors)]),
                opacity=0.6,
                hovertemplate=f'{sensor}<br>%{{x}}<br>%{{y:.2f}}Â°C<extra></extra>'
            ),
            row=1, col=1
        )
    
    # Linha de referÃªncia 30Â°C
    fig.add_hline(
        y=30, line_dash="dash", line_color="red",
        annotation_text="Limite 30Â°C", annotation_position="right",
        row=1, col=1
    )
    
    # GrÃ¡fico 2: MÃ©dia e faixa
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df["temp_interna_media"],
            name="MÃ©dia",
            mode='lines',
            line=dict(width=2, color='blue'),
            hovertemplate='MÃ©dia<br>%{x}<br>%{y:.2f}Â°C<extra></extra>'
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df["temp_interna_min"],
            name="MÃ­nima",
            mode='lines',
            line=dict(width=1, color='lightblue', dash='dash'),
            hovertemplate='MÃ­nima<br>%{x}<br>%{y:.2f}Â°C<extra></extra>'
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df["temp_interna_max"],
            name="MÃ¡xima",
            mode='lines',
            line=dict(width=1, color='lightblue', dash='dash'),
            fill='tonexty',
            fillcolor='rgba(173, 216, 230, 0.3)',
            hovertemplate='MÃ¡xima<br>%{x}<br>%{y:.2f}Â°C<extra></extra>'
        ),
        row=2, col=1
    )
    
    if show_external and "temp_externa" in df.columns:
        fig.add_trace(
            go.Scatter(
                x=df.index,
                y=df["temp_externa"],
                name="Temperatura Externa",
                mode='lines',
                line=dict(width=2, color='orange', dash='dot'),
                hovertemplate='Externa<br>%{x}<br>%{y:.2f}Â°C<extra></extra>'
            ),
            row=2, col=1
        )
    
    fig.add_hline(
        y=30, line_dash="dash", line_color="red",
        annotation_text="Limite 30Â°C", annotation_position="right",
        row=2, col=1
    )
    
    fig.update_xaxes(
        title_text="Data/Hora", 
        row=2, col=1,
        type="date",  # ForÃ§a tipo de data no eixo X
        tickformat="%d/%m/%Y %H:%M"  # Formato brasileiro
    )
    fig.update_xaxes(
        type="date",  # ForÃ§a tipo de data no eixo X superior tambÃ©m
        tickformat="%d/%m/%Y %H:%M",
        row=1, col=1
    )
    fig.update_yaxes(title_text="Temperatura (Â°C)", row=1, col=1)
    fig.update_yaxes(title_text="Temperatura (Â°C)", row=2, col=1)
    fig.update_layout(
        height=700, 
        showlegend=True, 
        hovermode='x unified',
        xaxis=dict(type='date'),  # Garante tipo date no layout principal
        xaxis2=dict(type='date')   # Garante tipo date no segundo subplot
    )
    
    return fig

def plot_correlation_scatter(df, temp_int_col, temp_ext_col):
    """GrÃ¡fico de dispersÃ£o de correlaÃ§Ã£o"""
    data = df[[temp_int_col, temp_ext_col]].dropna()
    
    if len(data) < 10:
        return None
    
    # Calcula correlaÃ§Ã£o
    corr, p_value = stats.pearsonr(data[temp_ext_col], data[temp_int_col])
    
    # RegressÃ£o linear
    slope, intercept, r_value, _, _ = stats.linregress(data[temp_ext_col], data[temp_int_col])
    x_line = np.linspace(data[temp_ext_col].min(), data[temp_ext_col].max(), 100)
    y_line = slope * x_line + intercept
    
    fig = go.Figure()
    
    # Scatter plot
    fig.add_trace(
        go.Scatter(
            x=data[temp_ext_col],
            y=data[temp_int_col],
            mode='markers',
            marker=dict(
                size=4,
                color=data.index.astype(int),
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(title="Timestamp")
            ),
            hovertemplate='Externa: %{x:.2f}Â°C<br>Interna: %{y:.2f}Â°C<extra></extra>',
            name="MediÃ§Ãµes"
        )
    )
    
    # Linha de regressÃ£o
    fig.add_trace(
        go.Scatter(
            x=x_line,
            y=y_line,
            mode='lines',
            line=dict(color='red', width=2, dash='dash'),
            name=f'RegressÃ£o (RÂ²={r_value**2:.3f})'
        )
    )
    
    # Linha diagonal (y=x)
    min_temp = min(data[temp_ext_col].min(), data[temp_int_col].min())
    max_temp = max(data[temp_ext_col].max(), data[temp_int_col].max())
    fig.add_trace(
        go.Scatter(
            x=[min_temp, max_temp],
            y=[min_temp, max_temp],
            mode='lines',
            line=dict(color='gray', width=1, dash='dot'),
            name='y=x'
        )
    )
    
    fig.update_layout(
        title=f'CorrelaÃ§Ã£o: Externa vs Interna<br>Pearson r = {corr:.3f} (p = {p_value:.2e})',
        xaxis_title='Temperatura Externa (Â°C)',
        yaxis_title='Temperatura Interna MÃ©dia (Â°C)',
        height=500,
        hovermode='closest'
    )
    
    return fig

def plot_thermal_gradient(df, temp_int_col, temp_ext_col):
    """GrÃ¡fico de gradiente tÃ©rmico ao longo do tempo"""
    # Garante que o Ã­ndice Ã© DatetimeIndex (cria cÃ³pia para nÃ£o modificar original)
    df = df.copy()
    if not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index, errors="coerce")
        df = df[~df.index.isna()]
    
    data = df[[temp_int_col, temp_ext_col]].dropna()
    data["gradiente"] = data[temp_ext_col] - data[temp_int_col]
    
    fig = go.Figure()
    
    fig.add_trace(
        go.Scatter(
            x=data.index,
            y=data["gradiente"],
            mode='lines',
            name="Gradiente TÃ©rmico",
            line=dict(width=2, color='green'),
            fill='tozeroy',
            fillcolor='rgba(0, 255, 0, 0.2)',
            hovertemplate='%{x}<br>Gradiente: %{y:.2f}Â°C<extra></extra>'
        )
    )
    
    # Linha de referÃªncia zero
    fig.add_hline(y=0, line_dash="dash", line_color="gray")
    
    # Linhas de referÃªncia para eficiÃªncia
    fig.add_hline(y=2, line_dash="dot", line_color="orange", annotation_text="Bom isolamento")
    fig.add_hline(y=5, line_dash="dot", line_color="green", annotation_text="Excelente isolamento")
    
    fig.update_layout(
        title="Gradiente TÃ©rmico (Externa - Interna)",
        xaxis_title="Data/Hora",
        yaxis_title="Gradiente (Â°C)",
        height=400,
        hovermode='x unified',
        xaxis=dict(
            type='date',
            tickformat="%d/%m/%Y %H:%M"
        )
    )
    
    return fig

def plot_heatmap_by_period(df, temp_int_col):
    """Mapa de calor por perÃ­odo do dia"""
    data = df[[temp_int_col]].copy().dropna()
    data["hora"] = data.index.hour
    data["dia_semana"] = data.index.strftime("%A")
    data["dia"] = data.index.date
    
    # Cria matriz para heatmap
    pivot_data = data.pivot_table(
        values=temp_int_col,
        index="hora",
        columns="dia",
        aggfunc="mean"
    )
    
    fig = go.Figure(data=go.Heatmap(
        z=pivot_data.values,
        x=[str(d) for d in pivot_data.columns],
        y=pivot_data.index,
        colorscale='RdYlBu_r',
        colorbar=dict(title="Temperatura (Â°C)"),
        hovertemplate='Hora: %{y}<br>Dia: %{x}<br>Temp: %{z:.2f}Â°C<extra></extra>'
    ))
    
    fig.update_layout(
        title="Mapa de Calor - Temperatura por Hora e Dia",
        xaxis_title="Data",
        yaxis_title="Hora do Dia",
        height=400
    )
    
    return fig

def plot_sensor_comparison(df, sensor_cols):
    """Boxplot comparativo dos sensores"""
    data = []
    labels = []
    for sensor in sensor_cols:
        values = df[sensor].dropna()
        if len(values) > 0:
            data.append(values)
            labels.append(sensor)
    
    fig = go.Figure()
    
    for i, (values, label) in enumerate(zip(data, labels)):
        fig.add_trace(
            go.Box(
                y=values,
                name=label,
                boxpoints='outliers',
                hovertemplate=f'{label}<br>%{{y:.2f}}Â°C<extra></extra>'
            )
        )
    
    fig.add_hline(y=30, line_dash="dash", line_color="red", annotation_text="Limite 30Â°C")
    
    fig.update_layout(
        title="DistribuiÃ§Ã£o de Temperatura por Sensor",
        xaxis_title="Sensor",
        yaxis_title="Temperatura (Â°C)",
        height=500
    )
    
    return fig

def plot_excursions_over_time(df, sensor_cols, threshold=30):
    """GrÃ¡fico de excursÃµes acima do limite"""
    fig = go.Figure()
    
    for sensor in sensor_cols:
        data = df[[sensor]].dropna()
        excursions = (data[sensor] > threshold).astype(int)
        # Agrupa por dia mantendo o Ã­ndice como datetime
        excursions_daily = excursions.groupby(excursions.index.date).sum()
        # Converte as datas de volta para datetime para plotagem
        dates = pd.to_datetime(excursions_daily.index)
        
        fig.add_trace(
            go.Scatter(
                x=dates,
                y=excursions_daily.values,
                mode='lines+markers',
                name=sensor,
                hovertemplate=f'{sensor}<br>%{{x}}<br>%{{y}} minutos acima de {threshold}Â°C<extra></extra>'
            )
        )
    
    fig.update_layout(
        title=f"ExcursÃµes Acima de {threshold}Â°C por Dia",
        xaxis_title="Data",
        yaxis_title="Minutos acima do limite",
        height=400,
        hovermode='x unified',
        xaxis=dict(
            type='date',
            tickformat="%d/%m/%Y"
        )
    )
    
    return fig

# ============================================================================
# INTERFACE STREAMLIT
# ============================================================================

def main():
    st.title("Dashboard de AnÃ¡lise TÃ©rmica - Tecnologia 3TC")
    st.markdown("---")
    
    # Sidebar - ConfiguraÃ§Ãµes
    st.sidebar.header("ConfiguraÃ§Ãµes")
    
    # DiretÃ³rio fixo dos CSVs
    csv_dir = "Dados de entrada prÃ© instalaÃ§Ã£o"
    
    fonte_externa = st.sidebar.selectbox(
        "Fonte dos dados de temperatura externa",
        ["Nenhum", "Arquivo CSV", "API Open-Meteo"],
        index=2
    )
    
    external_csv = ""
    selected_location: Optional[Dict] = None
    
    if fonte_externa == "Arquivo CSV":
        external_csv = st.sidebar.text_input(
            "Arquivo CSV Temperatura Externa",
            value="",
            help="Informe um arquivo com timestamp e temperatura externa."
        )
    elif fonte_externa == "API Open-Meteo":
        # Inicializa estados
        if 'selected_city' not in st.session_state:
            st.session_state['selected_city'] = None
        
        selected_location = None
        
        # Arquivo onde as cidades sÃ£o salvas
        cidades_file = Path("cidades_openmeteo.csv")
        
        # FunÃ§Ã£o para buscar cidades na API e salvar no arquivo
        def _buscar_e_salvar_cidades():
            """Busca cidades na API e salva no arquivo CSV"""
            cidades_iniciais = [
                "Cabedelo, PB", "JoÃ£o Pessoa, PB", "Campina Grande, PB",
                "Recife, PE", "Salvador, BA", "Fortaleza, CE",
                "SÃ£o Paulo, SP", "Rio de Janeiro, RJ", "BrasÃ­lia, DF",
                "Belo Horizonte, MG", "Curitiba, PR", "Porto Alegre, RS",
                "Manaus, AM", "BelÃ©m, PA", "Natal, RN"
            ]
            
            todas_cidades = []
            cache_dict = {}
            
            for cidade_query in cidades_iniciais:
                try:
                    results = geocode_city(cidade_query, count=3, country_code="BR")
                    if results:
                        for cidade in results:
                            nome = cidade.get('name', '')
                            admin = cidade.get('admin1') or cidade.get('country', '')
                            pais = cidade.get('country_code', '')
                            label = f"{nome}"
                            if admin:
                                label += f", {admin}"
                            if pais:
                                label += f" ({pais.upper()})"
                            
                            # Evita duplicatas
                            if label not in cache_dict:
                                cache_dict[label] = True
                                todas_cidades.append({
                                    'label': label,
                                    'name': nome,
                                    'admin1': cidade.get('admin1', ''),
                                    'country': cidade.get('country', ''),
                                    'country_code': pais,
                                    'latitude': cidade.get('latitude', 0),
                                    'longitude': cidade.get('longitude', 0),
                                    'timezone': cidade.get('timezone', ''),
                                    'elevation': cidade.get('elevation', 0)
                                })
                except Exception:
                    continue
            
            # Salva no arquivo CSV
            if todas_cidades:
                df = pd.DataFrame(todas_cidades)
                df = df.sort_values('label')
                df.to_csv(cidades_file, index=False, encoding='utf-8-sig')
                return df
            return None
        
        # Carrega cidades do arquivo (ou busca e salva se nÃ£o existir)
        if 'cities_loaded' not in st.session_state:
            with st.sidebar:
                with st.spinner("ðŸ” Carregando cidades..."):
                    if cidades_file.exists():
                        try:
                            df_cidades = pd.read_csv(cidades_file, encoding='utf-8-sig')
                        except Exception as e:
                            st.warning(f"Erro ao ler arquivo de cidades: {e}. Buscando na API...")
                            df_cidades = _buscar_e_salvar_cidades()
                    else:
                        st.info("ðŸ“¥ Arquivo de cidades nÃ£o encontrado. Buscando na API...")
                        df_cidades = _buscar_e_salvar_cidades()
                    
                    if df_cidades is not None and len(df_cidades) > 0:
                        # Prepara dicionÃ¡rio de cidades
                        cities_dict = {}
                        cities_options = []
                        
                        for _, row in df_cidades.iterrows():
                            label = row['label']
                            cidade = {
                                'name': row['name'],
                                'admin1': row.get('admin1', ''),
                                'country': row.get('country', ''),
                                'country_code': row.get('country_code', 'BR'),
                                'latitude': float(row.get('latitude', 0)),
                                'longitude': float(row.get('longitude', 0)),
                                'timezone': row.get('timezone', ''),
                                'elevation': float(row.get('elevation', 0))
                            }
                            cities_dict[label] = cidade
                            cities_options.append(label)
                        
                        # Salva no session_state
                        st.session_state['cities_dict'] = cities_dict
                        st.session_state['cities_options'] = cities_options
                        
                        # Define Cabedelo como cidade padrÃ£o selecionada
                        if not st.session_state.get('selected_city'):
                            for label, cidade in cities_dict.items():
                                nome = cidade.get('name', '').lower()
                                admin = cidade.get('admin1', '').lower()
                                if 'cabedelo' in nome and ('paraÃ­ba' in admin or 'paraiba' in admin):
                                    st.session_state['selected_city'] = cidade
                                    break
                        
                        st.session_state['cities_loaded'] = True
                    else:
                        st.error("NÃ£o foi possÃ­vel carregar as cidades.")
                        st.session_state['cities_loaded'] = True
        
        # Prepara lista de opÃ§Ãµes para o selectbox
        opcoes_cidades = st.session_state.get('cities_options', []).copy()
        
        # Garante que hÃ¡ pelo menos uma opÃ§Ã£o
        if not opcoes_cidades:
            opcoes_cidades = ["Carregando..."]
        
        # Determina Ã­ndice padrÃ£o (cidade selecionada)
        default_idx = 0
        if st.session_state.get('selected_city'):
            selected = st.session_state['selected_city']
            nome = selected.get('name', '')
            admin = selected.get('admin1') or selected.get('country', '')
            pais = selected.get('country_code', '')
            label_atual = f"{nome}"
            if admin:
                label_atual += f", {admin}"
            if pais:
                label_atual += f" ({pais.upper()})"
            
            if label_atual in opcoes_cidades:
                default_idx = opcoes_cidades.index(label_atual)
        
        # SELECTBOX ÃšNICO - o Streamlit permite digitar para filtrar opÃ§Ãµes existentes
        cidade_selecionada = st.sidebar.selectbox(
            "ðŸŒ Cidade",
            options=opcoes_cidades,
            index=default_idx if opcoes_cidades else 0,
            key="cidade_selectbox_final",
            help="Digite para filtrar ou selecione uma cidade. Cabedelo jÃ¡ estÃ¡ carregado."
        )
        
        # Atualiza cidade selecionada
        cities_dict = st.session_state.get('cities_dict', {})
        if cidade_selecionada and cidade_selecionada in cities_dict:
            selected_location = cities_dict[cidade_selecionada]
            st.session_state['selected_city'] = selected_location
        
        # Garante selected_location
        if st.session_state.get('selected_city') and not selected_location:
            selected_location = st.session_state['selected_city']
    
    temp_min = st.sidebar.number_input("Temperatura mÃ­nima ideal (Â°C)", value=15.0)
    temp_max = st.sidebar.number_input("Temperatura mÃ¡xima ideal (Â°C)", value=30.0)
    
    # Carrega dados
    with st.spinner("Carregando dados..."):
        internal_df, sensor_cols, metadados_sensores = load_internal_data(Path(csv_dir))
        
        external_df = None
        external_success = None
        external_error = None
        
        if internal_df is not None and len(internal_df):
            if fonte_externa == "Arquivo CSV" and external_csv:
                try:
                    external_df = load_external_data(Path(external_csv))
                    if external_df is None or external_df.empty:
                        external_error = "NÃ£o foi possÃ­vel interpretar o CSV de temperatura externa."
                    else:
                        external_success = f"Temperatura externa carregada de {external_csv}."
                except Exception as exc:
                    external_error = f"Erro ao ler CSV externo: {exc}"
                    external_df = None
            elif fonte_externa == "API Open-Meteo":
                if not selected_location:
                    external_error = "âš ï¸ Selecione uma cidade para buscar dados de temperatura externa."
                else:
                    try:
                        start_ts = internal_df.index.min()
                        end_ts = internal_df.index.max()
                        
                        # Valida coordenadas
                        lat = selected_location.get("latitude")
                        lon = selected_location.get("longitude")
                        if lat is None or lon is None:
                            external_error = "Coordenadas invÃ¡lidas para a cidade selecionada."
                        else:
                            with st.spinner(f"ðŸŒ¡ï¸ Buscando dados de temperatura para {selected_location.get('name')}..."):
                                external_df = fetch_external_temperature_from_api(
                                    lat,
                                    lon,
                                    start_ts,
                                    end_ts,
                                    selected_location.get("timezone")
                                )
                            
                            if external_df is None or external_df.empty:
                                external_error = (
                                    f"API nÃ£o retornou dados de temperatura para {selected_location.get('name')} "
                                    f"no perÃ­odo de {start_ts.date()} a {end_ts.date()}. "
                                    f"Verifique se as datas estÃ£o dentro do perÃ­odo disponÃ­vel na API."
                                )
                            else:
                                external_success = (
                                    f"âœ… Temperatura externa obtida via Open-Meteo para {selected_location.get('name')} "
                                    f"({selected_location.get('country_code')}). "
                                    f"Total de {len(external_df)} mediÃ§Ãµes carregadas."
                                )
                    except Exception as exc:
                        external_error = f"âŒ Falha ao consultar API Open-Meteo: {str(exc)}"
                        external_df = None
            
            if external_df is not None and not external_df.empty:
                internal_df = internal_df.join(external_df, how="outer")
                if "temp_externa" in internal_df.columns:
                    internal_df["temp_externa"] = pd.to_numeric(
                        internal_df["temp_externa"],
                        errors="coerce"
                    )
                    internal_df["temp_externa"] = (
                        internal_df["temp_externa"]
                        .interpolate(method="time")
                        .ffill()
                        .bfill()
                    )
                    internal_df = internal_df.sort_index()
        
        # Exibe mensagens de sucesso ou erro
        if external_success:
            st.sidebar.success(external_success)
        if external_error:
            st.sidebar.error(f"âš ï¸ {external_error}")
    
    # VariÃ¡vel de exportaÃ§Ã£o serÃ¡ definida depois dos filtros

    if internal_df is None or len(sensor_cols) == 0:
        st.error("Nenhum dado de sensor encontrado. Verifique se hÃ¡ arquivos CSV na pasta 'Dados de entrada prÃ© instalaÃ§Ã£o'.")
        return
    
    # InformaÃ§Ãµes gerais
    st.header("VisÃ£o Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("NÃºmero de Sensores", len(sensor_cols))
    
    with col2:
        st.metric("Total de MediÃ§Ãµes", f"{len(internal_df):,}")
    
    with col3:
        if "temp_interna_media" in internal_df.columns:
            temp_media = internal_df["temp_interna_media"].mean()
            st.metric("Temperatura MÃ©dia Interna", f"{temp_media:.2f}Â°C")
    
    with col4:
        if "temp_interna_media" in internal_df.columns:
            excursoes = (internal_df["temp_interna_media"] > temp_max).sum()
            st.metric("ExcursÃµes Acima do Limite", f"{excursoes}")
    
    # Filtros de data
    st.sidebar.markdown("---")
    st.sidebar.header("Filtros")
    
    min_date = internal_df.index.min().date()
    max_date = internal_df.index.max().date()
    
    date_range = st.sidebar.date_input(
        "PerÃ­odo de AnÃ¡lise",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )
    
    if isinstance(date_range, tuple) and len(date_range) == 2:
        filtered_df = internal_df[
            (internal_df.index.date >= date_range[0]) & 
            (internal_df.index.date <= date_range[1])
        ].copy()
    else:
        filtered_df = internal_df.copy()
    
    # SeleÃ§Ã£o de sensores
    selected_sensors = st.sidebar.multiselect(
        "Sensores para anÃ¡lise",
        options=sensor_cols,
        default=sensor_cols
    )
    
    # Recalcula valores mÃ©dios usando apenas os sensores selecionados
    if selected_sensors:
        filtered_df["temp_interna_media"] = filtered_df[selected_sensors].mean(axis=1)
        filtered_df["temp_interna_min"] = filtered_df[selected_sensors].min(axis=1)
        filtered_df["temp_interna_max"] = filtered_df[selected_sensors].max(axis=1)
        filtered_df["temp_interna_std"] = filtered_df[selected_sensors].std(axis=1)
    else:
        # Se nenhum sensor selecionado, mantÃ©m valores originais ou define como NaN
        filtered_df["temp_interna_media"] = np.nan
        filtered_df["temp_interna_min"] = np.nan
        filtered_df["temp_interna_max"] = np.nan
        filtered_df["temp_interna_std"] = np.nan
    
    # BotÃ£o de exportar (Ãºltimo do menu)
    st.sidebar.markdown("---")
    exportar_excel = st.sidebar.button("ðŸ“¤ Exportar mediÃ§Ãµes (Excel)", use_container_width=True)
    
    # LÃ³gica de exportaÃ§Ã£o (executada DEPOIS do botÃ£o ser criado)
    if exportar_excel:
        if internal_df is not None and sensor_cols:
            hum_map = {
                sensor: f"{sensor}_umidade"
                for sensor in sensor_cols
                if f"{sensor}_umidade" in internal_df.columns
            }
            temp_long = (
                internal_df[sensor_cols]
                .reset_index()
                .rename(columns={"index": "timestamp"})
                .melt(id_vars="timestamp", var_name="sensor", value_name="temperatura")
                .dropna(subset=["temperatura"])
            )
            if temp_long.empty:
                st.sidebar.warning("NÃ£o hÃ¡ mediÃ§Ãµes vÃ¡lidas para exportar.")
            else:
                # Adiciona temperatura externa se disponÃ­vel
                if "temp_externa" in internal_df.columns:
                    temp_externa_df = (
                        internal_df[["temp_externa"]]
                        .reset_index()
                        .rename(columns={"index": "timestamp"})
                        .dropna(subset=["temp_externa"])
                    )
                    # Merge com temperatura externa por timestamp
                    export_df = temp_long.merge(
                        temp_externa_df,
                        on="timestamp",
                        how="left"
                    )
                else:
                    export_df = temp_long.copy()
                    export_df["temp_externa"] = pd.NA
                
                # Adiciona umidade se disponÃ­vel
                if hum_map:
                    hum_cols = list(hum_map.values())
                    rename_map = {col: sensor for sensor, col in hum_map.items()}
                    hum_long = (
                        internal_df[hum_cols]
                        .reset_index()
                        .rename(columns={"index": "timestamp"})
                        .rename(columns=rename_map)
                        .melt(id_vars="timestamp", var_name="sensor", value_name="umidade")
                    )
                    export_df = export_df.merge(hum_long, on=["timestamp", "sensor"], how="left")
                else:
                    export_df["umidade"] = pd.NA
                
                # Reordena colunas: timestamp, sensor, temperatura, temp_externa, umidade
                col_order = ["timestamp", "sensor", "temperatura"]
                if "temp_externa" in export_df.columns:
                    col_order.append("temp_externa")
                if "umidade" in export_df.columns:
                    col_order.append("umidade")
                export_df = export_df[col_order]

                buffer = BytesIO()
                export_df.to_excel(buffer, index=False)
                buffer.seek(0)
                st.sidebar.download_button(
                    label="Baixar Excel Gerado",
                    data=buffer,
                    file_name="medicoes_sensores.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.sidebar.warning("Carregue os dados dos sensores antes de exportar.")
    
    # Tabs principais
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "EvoluÃ§Ã£o Temporal",
        "CorrelaÃ§Ã£o",
        "Gradiente TÃ©rmico",
        "Mapa de Calor",
        "ComparaÃ§Ã£o de Sensores",
        "ExcursÃµes",
        "Metadados dos Sensores",
        "MÃ©tricas Chave"
    ])
    
    with tab1:
        st.subheader("EvoluÃ§Ã£o da Temperatura ao Longo do Tempo")
        show_external = st.checkbox("Mostrar Temperatura Externa", value=True)
        
        # Filtra sensores selecionados
        if selected_sensors:
            plot_df = filtered_df[selected_sensors + ["temp_interna_media", "temp_interna_min", "temp_interna_max"]]
            if "temp_externa" in filtered_df.columns and show_external:
                plot_df["temp_externa"] = filtered_df["temp_externa"]
        else:
            plot_df = filtered_df[["temp_interna_media", "temp_interna_min", "temp_interna_max"]]
            if "temp_externa" in filtered_df.columns and show_external:
                plot_df["temp_externa"] = filtered_df["temp_externa"]
        
        fig = plot_temperature_over_time(plot_df, selected_sensors if selected_sensors else [], show_external)
        st.plotly_chart(fig, use_container_width=True)
        
        # EstatÃ­sticas resumidas
        if "temp_interna_media" in filtered_df.columns:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("MÃ©dia", f"{filtered_df['temp_interna_media'].mean():.2f}Â°C")
            with col2:
                st.metric("MÃ­nima", f"{filtered_df['temp_interna_media'].min():.2f}Â°C")
            with col3:
                st.metric("MÃ¡xima", f"{filtered_df['temp_interna_media'].max():.2f}Â°C")
            with col4:
                st.metric("Desvio PadrÃ£o", f"{filtered_df['temp_interna_media'].std():.2f}Â°C")
    
    with tab2:
        st.subheader("CorrelaÃ§Ã£o: Temperatura Externa vs Interna")
        
        if "temp_externa" in filtered_df.columns and "temp_interna_media" in filtered_df.columns:
            fig = plot_correlation_scatter(filtered_df, "temp_interna_media", "temp_externa")
            if fig:
                st.plotly_chart(fig, use_container_width=True)
                
                # MÃ©tricas de correlaÃ§Ã£o
                data = filtered_df[["temp_interna_media", "temp_externa"]].dropna()
                if len(data) > 10:
                    corr_pearson, p_pearson = stats.pearsonr(data["temp_externa"], data["temp_interna_media"])
                    corr_spearman, p_spearman = stats.spearmanr(data["temp_externa"], data["temp_interna_media"])
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("CorrelaÃ§Ã£o de Pearson", f"{corr_pearson:.4f}", 
                                 delta=f"p = {p_pearson:.2e}")
                    with col2:
                        st.metric("CorrelaÃ§Ã£o de Spearman", f"{corr_spearman:.4f}",
                                 delta=f"p = {p_spearman:.2e}")
                    
                    # InterpretaÃ§Ã£o
                    if abs(corr_pearson) > 0.7:
                        st.info("**CorrelaÃ§Ã£o Forte**: A temperatura interna estÃ¡ fortemente dependente da externa. O isolamento pode ser melhorado.")
                    elif abs(corr_pearson) > 0.4:
                        st.warning("**CorrelaÃ§Ã£o Moderada**: A temperatura interna tem dependÃªncia moderada da externa.")
                    else:
                        st.success("**CorrelaÃ§Ã£o Fraca**: A temperatura interna Ã© pouco dependente da externa. Bom isolamento!")
        else:
            st.warning("Ã¢Å¡Â Ã¯Â¸Â Dados de temperatura externa nÃ£o disponÃ­veis. Carregue um arquivo CSV com dados externos.")
    
    with tab3:
        st.subheader("Gradiente TÃ©rmico (Externa - Interna)")
        
        if "temp_externa" in filtered_df.columns and "temp_interna_media" in filtered_df.columns:
            fig = plot_thermal_gradient(filtered_df, "temp_interna_media", "temp_externa")
            st.plotly_chart(fig, use_container_width=True)
            
            # EstatÃ­sticas do gradiente
            data = filtered_df[["temp_interna_media", "temp_externa"]].dropna()
            gradiente = data["temp_externa"] - data["temp_interna_media"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Gradiente MÃ©dio", f"{gradiente.mean():.2f}Â°C")
            with col2:
                st.metric("Gradiente MÃ­nimo", f"{gradiente.min():.2f}Â°C")
            with col3:
                st.metric("Gradiente MÃ¡ximo", f"{gradiente.max():.2f}Â°C")
            
            # ClassificaÃ§Ã£o
            if gradiente.mean() > 5:
                st.success("**Excelente Isolamento**: Gradiente mÃ©dio > 5Â°C")
            elif gradiente.mean() > 2:
                st.info("**Bom Isolamento**: Gradiente mÃ©dio entre 2-5Â°C")
            elif gradiente.mean() > 0:
                st.warning("**Isolamento Moderado**: Gradiente mÃ©dio entre 0-2Â°C")
            else:
                st.error("**Isolamento Ineficiente**: Gradiente negativo (interna mais quente que externa)")
        else:
            st.warning("Dados de temperatura externa nÃ£o disponÃ­veis.")
    
    with tab4:
        st.subheader("Mapa de Calor - Temperatura por Hora e Dia")
        if "temp_interna_media" in filtered_df.columns:
            fig = plot_heatmap_by_period(filtered_df, "temp_interna_media")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Dados insuficientes para mapa de calor.")
    
    with tab5:
        st.subheader("ComparaÃ§Ã£o entre Sensores")
        if selected_sensors:
            plot_df = filtered_df[selected_sensors]
            fig = plot_sensor_comparison(plot_df, selected_sensors)
            st.plotly_chart(fig, use_container_width=True)
            
            # Tabela de estatÃ­sticas
            st.subheader("EstatÃ­sticas por Sensor")
            stats_data = []
            for sensor in selected_sensors:
                values = filtered_df[sensor].dropna()
                if len(values) > 0:
                    stats_data.append({
                        "Sensor": sensor,
                        "MÃ©dia (Â°C)": f"{values.mean():.2f}",
                        "MÃ­n (Â°C)": f"{values.min():.2f}",
                        "MÃ¡x (Â°C)": f"{values.max():.2f}",
                        "Desv. Pad. (Â°C)": f"{values.std():.2f}",
                        "ExcursÃµes > 30Â°C": int((values > temp_max).sum())
                    })
            
            if stats_data:
                st.dataframe(pd.DataFrame(stats_data), use_container_width=True)
        else:
            st.info("Selecione sensores na barra lateral para visualizar.")
    
    with tab6:
        st.subheader("AnÃ¡lise de ExcursÃµes Acima do Limite")
        if selected_sensors:
            fig = plot_excursions_over_time(filtered_df, selected_sensors, threshold=temp_max)
            st.plotly_chart(fig, use_container_width=True)
            
            # Resumo de excursÃµes
            st.subheader("Resumo de ExcursÃµes")
            exc_data = []
            for sensor in selected_sensors:
                values = filtered_df[sensor].dropna()
                if len(values) > 0:
                    excursoes = (values > temp_max).sum()
                    pct = (excursoes / len(values)) * 100
                    exc_data.append({
                        "Sensor": sensor,
                        "Total de ExcursÃµes": excursoes,
                        "% do Tempo": f"{pct:.2f}%",
                        "Temperatura MÃ¡xima": f"{values.max():.2f}Â°C"
                    })
            
            if exc_data:
                st.dataframe(pd.DataFrame(exc_data), use_container_width=True)
        else:
            st.info("Selecione sensores na barra lateral para visualizar.")
    
    with tab7:
        st.subheader("InformaÃ§Ãµes Detalhadas dos Sensores")
        
        if metadados_sensores:
            for sensor_id, metadata in sorted(metadados_sensores.items()):
                with st.expander(f" {sensor_id} - {metadata.get('modelo', 'N/A')}", expanded=False):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**InformaÃ§Ãµes do Dispositivo**")
                        if metadata.get("modelo"):
                            st.write(f"**Modelo:** {metadata['modelo']}")
                        if metadata.get("firmware"):
                            st.write(f"**Firmware:** {metadata['firmware']}")
                        if metadata.get("tipo_sensor"):
                            st.write(f"**Tipo:** {metadata['tipo_sensor']}")
                        if metadata.get("numero_viagem"):
                            st.write(f"**Viagem:** {metadata['numero_viagem']}")
                        if metadata.get("qualificacao"):
                            st.write(f"**QualificaÃ§Ã£o:** {metadata['qualificacao'][:50]}")
                    
                    with col2:
                        st.markdown("**ConfiguraÃ§Ã£o**")
                        if metadata.get("fuso_horario"):
                            st.write(f"**Fuso HorÃ¡rio:** {metadata['fuso_horario']}")
                        if metadata.get("intervalo_registro"):
                            st.write(f"**Intervalo:** {metadata['intervalo_registro']}")
                        if metadata.get("arquivo_criado"):
                            st.write(f"**Arquivo criado:** {metadata['arquivo_criado']}")
                    
                    # Alarmes
                    if metadata.get("alarmes"):
                        st.markdown("**Limites de Alarme**")
                        for alarme_tipo, alarme_info in metadata["alarmes"].items():
                            st.write(f"- **{alarme_tipo}:** {alarme_info.get('limite', 'N/A')}Â°C - Status: {alarme_info.get('status', 'N/A')}")
                    
                    # Resumo
                    if metadata.get("resumo"):
                        st.markdown("**Resumo EstatÃ­stico**")
                        resumo = metadata["resumo"]
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            if "max_temp" in resumo:
                                st.metric("MÃ¡ximo", f"{resumo['max_temp']:.1f}Â°C")
                        with col2:
                            if "min_temp" in resumo:
                                st.metric("MÃ­nimo", f"{resumo['min_temp']:.1f}Â°C")
                        with col3:
                            if "media_temp" in resumo:
                                st.metric("MÃ©dia", f"{resumo['media_temp']:.1f}Â°C")
                        with col4:
                            if "mkt" in resumo:
                                st.metric("MKT", f"{resumo['mkt']:.1f}Â°C")
                        
                        if "leituras_atuais" in resumo:
                            st.write(f"**Total de Leituras:** {resumo['leituras_atuais']:,}")
                        if "primeira_leitura" in resumo:
                            st.write(f"**Primeira Leitura:** {resumo['primeira_leitura']}")
                        if "ultima_leitura" in resumo:
                            st.write(f"**Ãšltima Leitura:** {resumo['ultima_leitura']}")
        else:
            st.info("Nenhum metadado extraÃ­do dos CSVs.")
    

    with tab8:
        st.subheader("MÃ©tricas Chave de Desempenho TÃ©rmico")
        metricas = calcular_metricas_energeticas(filtered_df, temp_max)
        if metricas["delta_t_medio"] is None:
            st.warning("Ã‰ necessÃ¡rio carregar temperatura interna mÃ©dia e temperatura externa para calcular as mÃ©tricas.")
        else:
            ajuda_textos = {
                "delta_t_medio": (
                    "DiferenÃ§a mÃ©dia entre a temperatura interna e a externa. "
                    "Valores positivos indicam que o ambiente interno se mantÃ©m mais quente que o exterior; "
                    "quanto menor, melhor o isolamento."
                ),
                "delta_t_p95": (
                    "Valor referente ao percentil 95 da diferenÃ§a interna-externa. "
                    "Representa os piores 5% das situaÃ§Ãµes de transferÃªncia tÃ©rmica."
                ),
                "graus_hora_acima_limite": (
                    "Grau-hora acima do limite mÃ¡ximo configurado. "
                    "Ã‰ a soma, ponderada pelo tempo, dos excedentes de temperatura interna acima do limite. "
                    "Serve como estimativa da carga tÃ©rmica adicional que precisaria ser removida."
                ),
                "slope_temp_ext_int": (
                    "InclinaÃ§Ã£o da regressÃ£o linear entre temperatura externa (x) e interna (y). "
                    "Quanto menor o coeficiente (Â°C/Â°C), mais desacoplado o ambiente estÃ¡ das variaÃ§Ãµes externas."
                ),
                "corr_pearson": (
                    "CorrelaÃ§Ã£o de Pearson entre temperatura interna e externa. "
                    "PrÃ³ximo de 1 indica forte dependÃªncia; valores prÃ³ximos de 0 indicam bom isolamento."
                ),
                "lag_horas": (
                    "Defasagem temporal estimada entre oscilaÃ§Ãµes externas e resposta interna. "
                    "Valor positivo: o ambiente interno reage com atraso Ã s mudanÃ§as externas. "
                    "Valores baixos sugerem que a temperatura interna segue rapidamente a externa."
                )
            }

            def _fmt(valor: Optional[float], formato: str) -> Optional[str]:
                if valor is None or pd.isna(valor):
                    return None
                return formato.format(valor)

            col_a, col_b, col_c = st.columns(3)
            with col_a:
                render_metric_with_help(
                    "Î”T mÃ©dio (Â°C)",
                    _fmt(metricas["delta_t_medio"], "{:.2f} Â°C"),
                    ajuda_textos["delta_t_medio"]
                )
                render_metric_with_help(
                    "Î”T (p95) (Â°C)",
                    _fmt(metricas["delta_t_p95"], "{:.2f} Â°C"),
                    ajuda_textos["delta_t_p95"]
                )
            with col_b:
                render_metric_with_help(
                    "Graus-hora acima do limite",
                    _fmt(metricas["graus_hora_acima_limite"], "{:.1f} Â°CÂ·h"),
                    ajuda_textos["graus_hora_acima_limite"]
                )
                render_metric_with_help(
                    "InclinaÃ§Ã£o interna vs externa",
                    _fmt(metricas["slope_temp_ext_int"], "{:.2f} Â°C/Â°C"),
                    ajuda_textos["slope_temp_ext_int"]
                )
            with col_c:
                render_metric_with_help(
                    "CorrelaÃ§Ã£o (Pearson)",
                    _fmt(metricas["corr_pearson"], "{:.3f}"),
                    ajuda_textos["corr_pearson"]
                )
                render_metric_with_help(
                    "Defasagem estimada",
                    _fmt(metricas["lag_horas"], "{:.2f} h"),
                    ajuda_textos["lag_horas"]
                )

            st.caption(
                "As mÃ©tricas consideram o intervalo filtrado. Para anÃ¡lise comparativa futura, "
                "carregue tambÃ©m os dados dos sensores com a nova tecnologia e utilize os mesmos filtros."
            )


    # RodapÃ©
    st.markdown("---")
    st.markdown("**Dashboard de AnÃ¡lise TÃ©rmica 3TC** | Desenvolvido para comparaÃ§Ã£o antes/depois da implementaÃ§Ã£o")

if __name__ == "__main__":
    main()

